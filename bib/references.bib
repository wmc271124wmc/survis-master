@article{Shinn2023Reflexion,
   abstract = {This paper introduces Reflexion, a novel framework where language agents are reinforced through linguistic feedback rather than weight updates, by verbally reflecting on task feedback and storing these reflections in an episodic memory to enhance future decision-making. Key contributions include this "verbal reinforcement" paradigm, empirical evidence of self-reflection's utility in rapid learning for complex tasks, the introduction of the LeetcodeHardGym benchmark, and state-of-the-art results in code generation.},
   author = {Shinn, Noah and Cassano, Federico and Berman, Edward and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
   journal = {arXiv preprint},
   keywords = {type:method, self-improvement, verbal-reinforcement, code-generation, external-memory, reinforcement-learning},
   series = {arXiv:2303.11366v4},
   title = {Reflexion: Language Agents with Verbal Reinforcement Learning},
   url = {https://github.com/noahshinn024/reflexion},
   year = {2023}
}

@article{Li2023CAMEL,
   abstract = {This paper introduces CAMEL, a novel "role-playing" communicative agent framework designed to facilitate autonomous cooperation among large language model (LLM) agents and explore their "cognitive" processes. The core concept involves using "inception prompting"—comprising task specifier, assistant system, and user system prompts—to guide chat agents (an AI assistant and an AI user) toward completing a specified task derived from an initial human idea, while maintaining alignment with human intentions and minimizing direct human intervention.},
   author = {Li, Guohao and Hammoud, Hasan Abed Al Kader and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
   journal = {arXiv preprint},
   keywords = {type:method, role-based, inception-prompting, code-generation, in-context-experience, cooperative-agents},
   series = {arXiv:2303.17760v2},
   title = {CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
   url = {https://github.com/camel-ai/camel},
   year = {2023}
}

@article{Fu2023Negotiation,
   abstract = {This paper investigates whether multiple Large Language Models (LLMs) can autonomously improve each other's negotiation skills through self-play and AI-generated feedback. The core concept involves two LLMs role-playing as a buyer and a seller negotiating over a product, with a third LLM acting as a critic providing natural language feedback to one player for strategy improvement in subsequent rounds, a method termed In-Context Learning from AI Feedback (ICL-AIF).},
   author = {Fu, Yao and Khot, Tushar and Peng, Hao and Lapata, Mirella},
   journal = {arXiv preprint},
   keywords = {type:method, self-improvement, negotiation, self-play, in-context-experience, feedback-learning},
   series = {arXiv:2305.10142v1},
   title = {Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback},
   url = {https://github.com/FranxYao/GPT-Bargaining},
   year = {2023}
}

@article{Du2023Multiagent,
   abstract = {This paper introduces a method where multiple language model (LLM) instances engage in a multi-round debate to enhance the factual accuracy and reasoning capabilities of their responses. The core idea is that given a query, several LLM agents independently propose answers; subsequently, each agent critiques the others' responses and refines its own, iterating this process to converge on a common, improved final answer.},
   author = {Du, Yilun and Li, Shuang and Torralba, Antonio and Mordatch, Igor and Tenenbaum, Joshua B.},
   journal = {arXiv preprint},
   keywords = {type:method, debate-based, reasoning, factuality, no-explicit-memory, convergent-reasoning},
   series = {arXiv:2305.14325v1},
   title = {Improving Factuality and Reasoning in Language Models through Multiagent Debate},
   url = {https://composable-models.github.io/llm_debate/},
   year = {2023}
}

@article{Liang2023Divergent,
   abstract = {This paper introduces the "Degeneration-of-Thought" (DoT) problem, where Large Language Models (LLMs) in self-reflection cycles become entrenched in their initial, potentially incorrect, solutions and fail to generate novel thoughts. To counter this, the authors propose a Multi-Agent Debate (MAD) framework where multiple LLM agents (typically two debaters—affirmative and negative—and a judge) engage in a "tit for tat" argumentation process to foster divergent thinking and arrive at a more accurate solution.},
   author = {Liang, Tian and He, Zhiwei and Jiao, Wenxiang and others},
   journal = {arXiv preprint},
   keywords = {type:method, debate-based, reasoning, degeneration-of-thought, no-explicit-memory, divergent-thinking},
   series = {arXiv:2305.19118v4},
   title = {Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
   url = {https://github.com/Skytliang/Multi-Agents-Debate},
   year = {2023}
}

@article{Talebirad2023Collaboration,
   abstract = {This paper proposes a novel framework for enhancing Large Language Model (LLM) capabilities through a multi-agent system where multiple "Intelligent Generative Agents" (IGAs), each with distinct attributes (language model, role, state, creation/halting abilities) and access to plugins, collaborate to tackle complex tasks. The framework, represented as a graph of agents and plugins, supports dynamic agent addition, inter-agent and self-feedback mechanisms, stateless "oracle" agents for specific functions, and supervisory control.},
   author = {Talebirad, Yashar and Nadiri, Amirhossein},
   journal = {arXiv preprint},
   keywords = {type:framework, role-based, code-generation, plugin-integration, conceptual-architecture},
   series = {arXiv:2306.03314v1},
   title = {Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents},
   year = {2023}
}

@article{Wang2023CognitiveSynergy,
   abstract = {This paper introduces Solo Performance Prompting (SPP), a zero-shot method that enables a single Large Language Model (LLM) to act as a "cognitive synergist" by simulating multi-turn self-collaboration among multiple dynamically identified personas. This approach involves the LLM identifying relevant personas for a given task, engaging in a brainstorming phase where these personas share knowledge, and then undergoing an iterative collaboration led by an "AI Assistant" persona that proposes solutions and refines them based on feedback from other simulated personas.},
   author = {Wang, Zhenhailong and Mao, Shaoguang and Wu, Wenshan and Ge, Tao and Wei, Furu and Ji, Heng},
   journal = {arXiv preprint},
   keywords = {type:method, self-improvement, reasoning, multi-persona, cognitive-synergy, emergent-abilities},
   series = {arXiv:2307.05300v4},
   title = {Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration},
   url = {https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git},
   year = {2023}
}

@article{Hong2023MetaGPT,
   abstract = {This paper introduces MetaGPT, a meta-programming framework that integrates Standardized Operating Procedures (SOPs) into LLM-based multi-agent collaborations to enhance complex problem-solving, particularly in software development. MetaGPT assigns distinct roles (e.g., Product Manager, Architect, Engineer, QA Engineer) to agents who follow streamlined workflows, producing structured outputs like documents and diagrams rather than relying solely on unstructured dialogue, thus minimizing errors and hallucinations.},
   author = {Hong, Sirui and Zhuge, Mingchen and others},
   journal = {arXiv preprint},
   keywords = {type:system, role-based, code-generation, SOP, software-development, workflow-integration},
   series = {arXiv:2308.00352v7},
   title = {MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework},
   url = {https://github.com/geekan/MetaGPT},
   year = {2023}
}

@article{Chan2023ChatEval,
   abstract = {This paper introduces ChatEval, a multi-agent LLM framework designed to improve text evaluation by simulating collaborative human assessment processes. Recognizing the limitations of single LLM evaluators and the cost of human annotation, ChatEval employs a team of LLM agents, each assigned a distinct persona (e.g., Critic, Scientist), to autonomously discuss and evaluate the quality of generated text over multiple rounds.},
   author = {Chan, Chi-Min and Chen, Weize and others},
   journal = {arXiv preprint},
   keywords = {type:system, debate-based, evaluation, text-assessment, collaborative-assessment},
   series = {arXiv:2308.07201v1},
   title = {ChatEval: Towards Better LLM-Based Evaluators Through Multi-Agent Debate},
   url = {https://github.com/chanchimin/ChatEval},
   year = {2023}
}

@article{Xu2023Werewolf,
   abstract = {This paper proposes a tuning-free framework for enabling frozen Large Language Models (LLMs) to play communication games, using the game "Werewolf" as a case study. The core of the framework involves LLM agents for each game role making decisions based on comprehensive prompts that include game rules, role descriptions, recent and heuristically selected informative messages, an agent-generated reflection on the game state, and suggestions extracted from a pool of past game experiences.},
   author = {Xu, Yuzhuang and Wang, Shuo and Li, Peng and others},
   journal = {arXiv preprint},
   keywords = {type:framework, game-theoretic, negotiation, strategic-gameplay, external-memory, experience-pools},
   series = {arXiv:2309.04658v2},
   title = {Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf},
   url = {https://github.com/xuyuzhuang11/Werewolf},
   year = {2023}
}